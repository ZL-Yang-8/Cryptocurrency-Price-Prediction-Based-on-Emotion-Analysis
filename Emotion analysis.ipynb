{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import preprocessor as p\n",
    "import nltk\n",
    "import re\n",
    "import emojis\n",
    "import csv\n",
    "import collections\n",
    "from ekphrasis.classes.segmenter import Segmenter\n",
    "from textblob import TextBlob, Word\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "seg = Segmenter(corpus='twitter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the emotion corpus\n",
    "anger_dict = pd.read_csv('E:\\\\project_data\\\\tweet_data\\\\emotion_lexicon\\\\anger.csv',index_col=0, squeeze=True, encoding='utf-8').to_dict()\n",
    "anticipation_dict = pd.read_csv('E:\\\\project_data\\\\tweet_data\\\\emotion_lexicon\\\\anticipation.csv',index_col=0, squeeze=True, encoding='utf-8').to_dict()\n",
    "disgust_dict = pd.read_csv('E:\\\\project_data\\\\tweet_data\\\\emotion_lexicon\\\\disgust.csv',index_col=0, squeeze=True, encoding='utf-8').to_dict()\n",
    "fear_dict = pd.read_csv('E:\\\\project_data\\\\tweet_data\\\\emotion_lexicon\\\\fear.csv',index_col=0, squeeze=True, encoding='utf-8').to_dict()\n",
    "joy_dict = pd.read_csv('E:\\\\project_data\\\\tweet_data\\\\emotion_lexicon\\\\joy.csv',index_col=0, squeeze=True, encoding='utf-8').to_dict()\n",
    "sadness_dict = pd.read_csv('E:\\\\project_data\\\\tweet_data\\\\emotion_lexicon\\\\sadness.csv',index_col=0, squeeze=True, encoding='utf-8').to_dict()\n",
    "surprise_dict = pd.read_csv('E:\\\\project_data\\\\tweet_data\\\\emotion_lexicon\\\\surprise.csv',index_col=0, squeeze=True, encoding='utf-8').to_dict()\n",
    "trust_dict = pd.read_csv('E:\\\\project_data\\\\tweet_data\\\\emotion_lexicon\\\\trust.csv',index_col=0, squeeze=True, encoding='utf-8').to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the text in the hashtag\n",
    "def extract_hashtag_text(tweet):\n",
    "    tag_text = \"\"\n",
    "    tweet= re.findall(r'#(\\w+)', tweet)\n",
    "    for tag in tweet:\n",
    "        clean_tag=seg.segment(tag)\n",
    "        tag_text += (clean_tag + \" \")\n",
    "    return tag_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract text information in emoji\n",
    "def extract_emoji_text(tweet):\n",
    "    emoji_text = \"\"\n",
    "    emoji_list = emojis.get(tweet)\n",
    "    for emoji in emoji_list:\n",
    "        emoji = emojis.decode(emoji)\n",
    "        emoji = re.sub(r':', '', emoji) \n",
    "        emoji = re.sub(r'_', ' ', emoji) \n",
    "        emoji_text += (emoji + \" \")\n",
    "    return emoji_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean up irrelevant symbols in tweets\n",
    "def tweets_cleaner(tweet):\n",
    "    #Use preprocessor to clean up URLs, Hashtags and user mentions\n",
    "    tweet = p.clean(tweet)\n",
    "    #Clean up all numbers\n",
    "    tweet = re.sub(r'[0-9]*', '', tweet) \n",
    "    #Clean up all punctuation\n",
    "    tweet = re.sub(r'[^\\w\\s]', '', tweet) \n",
    "    #Lowercase letters\n",
    "    semiclean_tweet = tweet.lower()\n",
    "    return semiclean_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatization\n",
    "def lemmatization_without_stopwords(semiclean_tweet):\n",
    "    lemmatized_list=[]\n",
    "    #Use TextBlob to tokenize tweets\n",
    "    sent = TextBlob(semiclean_tweet)\n",
    "    tag_dict = {\"J\": 'a', \n",
    "                \"N\": 'n', \n",
    "                \"V\": 'v', \n",
    "                \"R\": 'r'}\n",
    "    #Realize lemmatization according to the corresponding POS\n",
    "    words_and_tags = [(w, tag_dict.get(pos[0], 'n')) for w, pos in sent.tags]\n",
    "    #Remove stopwords\n",
    "    for wd, tag in words_and_tags:\n",
    "        if wd  not in stopwords:\n",
    "            lemmatized_list.append(wd.lemmatize(tag))\n",
    "    return lemmatized_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get clean tweet word lists\n",
    "def get_clean_text(raw_daily_data):\n",
    "    \n",
    "    clean_text=[0]*len(raw_daily_data[\"text\"])\n",
    "    \n",
    "    for num, tweet in enumerate(raw_daily_data[\"text\"]):\n",
    "        t_ls = lemmatization_without_stopwords(tweets_cleaner(tweet))\n",
    "        e_ls = lemmatization_without_stopwords(extract_emoji_text(tweet))\n",
    "        h_ls = lemmatization_without_stopwords(extract_hashtag_text(tweet))\n",
    "        clean_text[num] = t_ls + e_ls + h_ls\n",
    "    \n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the emotion score of each tweet\n",
    "def get_emotion_score(dataframe,clean_text):\n",
    "    \n",
    "    anger_score = [0]*len(clean_text)\n",
    "    for i, clean in enumerate(clean_text):\n",
    "        counts = collections.Counter(clean)\n",
    "        for word, freq in counts.items():\n",
    "            anger_score[i] += anger_dict.get(word, 0) * freq\n",
    "\n",
    "    anticipation_score = [0]*len(clean_text)\n",
    "    for i, clean in enumerate(clean_text):\n",
    "        counts = collections.Counter(clean)\n",
    "        for word, freq in counts.items():\n",
    "            anticipation_score[i] += anticipation_dict.get(word, 0) * freq\n",
    "            \n",
    "    disgust_score = [0]*len(clean_text)\n",
    "    for i, clean in enumerate(clean_text):\n",
    "        counts = collections.Counter(clean)\n",
    "        for word, freq in counts.items():\n",
    "            disgust_score[i] += disgust_dict.get(word, 0) * freq\n",
    "    \n",
    "    fear_score = [0]*len(clean_text)\n",
    "    for i, clean in enumerate(clean_text):\n",
    "        counts = collections.Counter(clean)\n",
    "        for word, freq in counts.items():\n",
    "            fear_score[i] += fear_dict.get(word, 0) * freq\n",
    "    \n",
    "    joy_score = [0]*len(clean_text)\n",
    "    for i, clean in enumerate(clean_text):\n",
    "        counts = collections.Counter(clean)\n",
    "        for word, freq in counts.items():\n",
    "            joy_score[i] += joy_dict.get(word, 0) * freq\n",
    "    \n",
    "    sadness_score = [0]*len(clean_text)\n",
    "    for i, clean in enumerate(clean_text):\n",
    "        counts = collections.Counter(clean)\n",
    "        for word, freq in counts.items():\n",
    "            sadness_score[i] += sadness_dict.get(word, 0) * freq\n",
    "            \n",
    "    surprise_score = [0]*len(clean_text)\n",
    "    for i, clean in enumerate(clean_text):\n",
    "        counts = collections.Counter(clean)\n",
    "        for word, freq in counts.items():\n",
    "            surprise_score[i] += surprise_dict.get(word, 0) * freq\n",
    "    \n",
    "    trust_score = [0]*len(clean_text)\n",
    "    for i, clean in enumerate(clean_text):\n",
    "        counts = collections.Counter(clean)\n",
    "        for word, freq in counts.items():\n",
    "            trust_score[i] += trust_dict.get(word, 0) * freq\n",
    "            \n",
    "    dataframe['anger_score']=anger_score  \n",
    "    dataframe['anticipation_score']=anticipation_score\n",
    "    dataframe['disgust_score']=disgust_score\n",
    "    dataframe['fear_score']=fear_score\n",
    "    dataframe['joy_score']=joy_score\n",
    "    dataframe['sadness_score']=sadness_score\n",
    "    dataframe['surprise_score']=surprise_score\n",
    "    dataframe['trust_score']=trust_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the emotion score of the day\n",
    "def get_daily_emotion(emotion_df):\n",
    "    d_anger_score=0\n",
    "    d_anticipation_score=0\n",
    "    d_disgust_score=0\n",
    "    d_fear_score=0\n",
    "    d_joy_score=0\n",
    "    d_sadness_score=0\n",
    "    d_surprise_score=0\n",
    "    d_trust_score=0\n",
    "    \n",
    "    for i in range(0,len(emotion_df)):\n",
    "        d_anger_score += (1+0.01*emotion_df.iloc[i]['like_count'])*emotion_df.iloc[i]['anger_score']\n",
    "        #Use like_count as an additional weight for tweets, and each like represents 1% of the sentiment score\n",
    "        d_anticipation_score += (1+0.01*emotion_df.iloc[i]['like_count'])*emotion_df.iloc[i]['anticipation_score']\n",
    "        d_disgust_score +=(1+0.01*emotion_df.iloc[i]['like_count'])*emotion_df.iloc[i]['disgust_score']\n",
    "        d_fear_score +=(1+0.01*emotion_df.iloc[i]['like_count'])*emotion_df.iloc[i]['fear_score']\n",
    "        d_joy_score +=(1+0.01*emotion_df.iloc[i]['like_count'])*emotion_df.iloc[i]['joy_score']\n",
    "        d_sadness_score +=(1+0.01*emotion_df.iloc[i]['like_count'])*emotion_df.iloc[i]['sadness_score']\n",
    "        d_surprise_score +=(1+0.01*emotion_df.iloc[i]['like_count'])*emotion_df.iloc[i]['surprise_score']\n",
    "        d_trust_score +=(1+0.01*emotion_df.iloc[i]['like_count'])*emotion_df.iloc[i]['trust_score']\n",
    "    \n",
    "    return d_anger_score,d_anticipation_score,d_disgust_score,d_fear_score,d_joy_score,d_sadness_score,d_surprise_score,d_trust_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get valid tweet data\n",
    "def get_available_emotion(df):\n",
    "    available_daily_data = df[ (df['anger_score'] != 0) | (df['anticipation_score']!=0) | (df['disgust_score']!=0) | (df['fear_score']!=0)| (df['joy_score']!=0) | (df['sadness_score']!=0) | (df['surprise_score']!=0) | (df['trust_score'] != 0)]\n",
    "    return available_daily_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month= '1'\n",
    "coin='Bitcoin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input_path = 'E:\\\\project_data\\\\tweet_data\\\\#'+coin+'\\\\'+ month\n",
    "\n",
    "filenames = glob.glob(data_input_path + '\\\\*.csv') \n",
    "\n",
    "daily_emotion=pd.DataFrame(columns=('date','volume','available_volume','anger_score','anticipation_score','disgust_score','fear_score','joy_score','sadness_score','surprise_score','trust_score'))\n",
    "\n",
    "for filename in filenames:\n",
    "    daily_data = pd.read_csv(filename, index_col = None, header = 0)\n",
    "    \n",
    "    #Get date\n",
    "    date = daily_data['created_at'][0][0:10]\n",
    "    \n",
    "    clean_text = get_clean_text(daily_data)\n",
    "    \n",
    "    #Get sentiment score for each tweet of the day\n",
    "    get_emotion_score(daily_data ,clean_text)\n",
    "    \n",
    "    #Get the total sentiment score of the day\n",
    "    anger_score,anticipation_score,disgust_score,fear_score,joy_score,sadness_score,surprise_score,trust_score = get_daily_emotion(daily_data)\n",
    "    \n",
    "    #Tweets volume\n",
    "    volume=len(daily_data)\n",
    "    \n",
    "    #Available tweets volume (including specific emotions)\n",
    "    available_volume=len(get_available_emotion(daily_data))\n",
    "    \n",
    "    #Write daily data to file\n",
    "    daily_emotion= daily_emotion.append({'date' : date , 'volume' :volume , 'available_volume': available_volume,\n",
    "                                         'anger_score' : anger_score , 'anticipation_score' : anticipation_score ,\n",
    "                                         'disgust_score': disgust_score , 'fear_score' : fear_score ,\n",
    "                                         'joy_score' : joy_score , 'sadness_score': sadness_score,\n",
    "                                         'surprise_score' : surprise_score , 'trust_score': trust_score}, \n",
    "                                         ignore_index = True)\n",
    "    print(filename)\n",
    "\n",
    "#Output the emotion report of the current month\n",
    "daily_emotion.to_csv('E:\\\\project_data\\\\tweet_data\\\\#'+coin+'\\\\report\\\\'+month+\"Report.csv\",encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
